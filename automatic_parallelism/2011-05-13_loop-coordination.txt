
Revisiting loop coordination
----------------------------

Consider the right recursion transformation we already designed.
We will use the familiar map_foldl example, parallelised in the smart
way.  I have written it here without state variable notation.

map_foldl(_, _, [], Acc, Acc).
map_foldl(M, F, [X | Xs], Acc0, Acc),
    (
        M(X, Y),
        F(Y, Acc0, Acc1),
    &
        map_foldl(M, F, Xs, Acc1, Acc)
    ).

Here it is again after applying the dependant parallel conjunction
transformation so that we can see the future that was Acc1.  The
future is not pushed into the higher order call 'F'.  As we know
map_foldl will be duplicated and specialised so that the future can be
pushed into the recursive call.

map_foldl(_, _, [], Acc, Acc).
map_foldl(M, F, [X | Xs], Acc0, Acc) :-
    new_future(FutureAcc1),
    (
        M(X, Y),
        F(Y, Acc0, Acc1),
        signal(FutureAcc1, Acc1)
    &
        map_foldl_parallel(M, F, Xs, FutureAcc1, Acc)
    ).

map_foldl_parallel(_, _, [], FutureAcc0, Acc) :-
    wait(FutureAcc0, Acc).
map_foldl_parallel(M, F, [X | Xs], FutureAcc0, Acc) :-
    new_future(FutureAcc1),
    (
        M(X, Y),
        wait(FutureAcc0, Acc0),
        f(Y, Acc0, Acc1),
        signal(FutureAcc1, Acc1)
    &
        map_foldl_parallel(M, F, Xs, FutureAcc1, Acc)
    ).

Now, lets apply the right-recursive loop coordination transformation
that we're designing.  We'll consider the specialised form of
map_foldl for two reasons:
    1) What to do in a non-specialised form of similar code is simple
       to deduce.
    2) This transformation doesn't apply to the original code since it
       no-longer contains a recursive call.

map_foldl_parallel(M, F, L, FutureAcc0, Acc) :-
    % The compiler chooses a constant for the number of threads to
    % attempt to use, here we use eight threads.
    create_loop_control(8, LC),
    map_foldl_parallel_lc(LC, M, F, L, FutureAcc0, Acc).

map_foldl_parallel_lc(LC, _, _, [], FutureAcc0, Acc) :-
    % The base case.
    wait(FutureAcc0, Acc).
map_foldl_parallel_lc(LC, M, F, [X | Xs], FutureAcc0, Acc) :-
    new_future(FutureAcc1),
    (
        free_slot_in(LC, FS)
        % short_spark_queue
    ->
        spawn_off(FS, (
            M(X, Y),
            wait(FutureAcc0, Acc0),
            f(Y, Acc0, Acc1),
            signal(FutureAcc1, Acc1),
            join_and_terminate(FS, LC)
        ),
        map_foldl_parallel_lc(LC, M, F, Xs, FutureAcc1, Acc),
        % This barrier waits for the other job to complete, as it may
        % have written it's result to our stack (but it doesn't in
        % this example).
        join_and_continue(FS, LC)
    ;
        M(X, Y),
        wait(FutureAcc0, Acc0),
        f(Y, Acc0, Acc1),
        signal(FutureAcc1, Acc1),
        map_foldl_parallel_lc(LC, M, F, Xs, FutureAcc1, Acc)
    ).

The granularity control in this design won't work.  If the loop
iterates millions of times but each iteration is cheap, then the
overheads will still exceed the savings of parallelising each
iteration, even with the granularity control check here.  It only
helps when tasks are large enough but there aren't enough processors.

The solution below works better in cases where there is no shared
variable between the conjuncts.  When there is a dependant variable
(Acc1 in this case), there may not be enough overlap (especially when
M/2 is cheap) to overcome the overheads.  Even a non-specific
granularity control transformation can't improve cases like this
simply because the code is too linear, and probably shouldn't have
been parallelised at all.

pl(In, Out) :-
    create_loop_control(8, LC),
    pl'(LC, In, Out).

pl'(LC, In, Out) :-
    (
        finish_loop(LC),
        base case
    ;
        new_future(X),
        spawn_off(LC,
                  p(In, X),
        ),
        pl'(LC, In, X, TmpOut),
        ...,
        Out = ...
    ).

Left recursive loops can be transformed as follows:

pl(In, Out) :-
    pl'(LC, [], In, Out),

pl'(LC, !Sparks, In, Out) :-
    (
        base_case,
        create_loop_control(8, LC),
        spawn_sparks(LC, !.Sparks),
        finish_loop(LC)
    ;
        new_future(X),
        Spark = create_spark(p(In, X)),
        !:Sparks = [Spark | !.Sparks],
        pl'(LC, !Sparks, In, X, TmpOut),
        Out = ...
    ).

spawn_sparks(LC, Sparks) :-
    map(spawn(LC), Sparks).

In this transformation a future may not be consumed by pl' before
either the base case or is called or until after the call to pl'.
This is a significant limitation.
The right recursive transformation doesn't have this problem, but code
with this pattern already has a limited amount of parallelism.

The loop control is:

struct LoopControl {
    SparkQuues **queues;
    int        num_queues;
    int        outstanding_workers;
    bool       finish;
}

The builtins should be:

create_loop_control(N, LC) {
    % Setup loop control structure.
    LC->queues = allocate_queues(N);
    LC->num_queues = N;
    LC->outstanding_workers = N;
    LC->finish = NO;

    % XXX: the nth job will be late, this won't balance well.
    % This balance could be corrected by executing every Nth
    % computation locally, but that delays the creation of every task
    % after that, reducing the parallelism by 1/N.
    % But the current solution already looses this much parallelism in
    % dependant code because each Nth task won't be entered until all
    % the tasks have been put on queues.
    % The only solution that solves the balance problem is one with a
    % single task queue, but that has more overhead.
    Fork n-1 workers (see worker()) to work on n-1 of the queues.
}

worker(LC, N) {
    task = get_task(LC->queues[N]);
    if (task) {
        MR_SUCCESS = worker(LC, N);
        MR_GOTO(task);
    } else if (LC->finish) {
        ATOMIC(LC->outstanding_workers--);
    } else {
        Suspend, and wakeup once our queue has some work.
    }
}

spawn_off simply adds a task to a queue in a round-robin fashion.
It also wakes sleeping workers, an array of workers should be kept in the
loop control structure and filled in for sleeping workers.  (Workers
ought to be contexts).

finish_loop(LC) {
    # Become the Nth worker.
    N = LC->num_queues;
    
    % Tell the other workers that there is no more work so that they exit.
    LC->finish = YES;
    wakeup_sleeping_workers();

    % Finish this worker's work.
    worker(LC, N);

    % Wait until all the work is done.
    SleepUntil(LC->outstanding_workers == 0);
}
