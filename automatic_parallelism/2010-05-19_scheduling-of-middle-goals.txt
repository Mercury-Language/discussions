
Scheduling of Middle Goals
==========================

Consider a conjunction that we'd like to parallelise.

  expensive_call_a(A, B, C),
  D = B + C,
  expensive_call_b(D, E).

We can parallelise this in several obvious ways.

  expensive_call_a(A, B, C) &
  D = B + C &
  expensive_call_b(D, E).

  expensive_call_a(A, B, C) &
  (
    D = B + C,
    expensive_call_b(D, E)
  )

  (
    expensive_call_a(A, B, C),
    D = B + C
  ) &
  expensive_call_b(D, E).

Which one we choose depends on how early B and C are produced and how
late D is consumed.  However, there are other considerations.  One of
these is that there may be earlier goals within the conjunction that
we want to parallelise.  How they are scheduled will have an effect on
how when variables are produced for a and b.  In general the
scheduling of a later goal depends on the scheduling of an earlier
goal, but _never_ the other way around.

Other cases involve multiple goals between expensive calls.  We should
make the decision of how to schedule each one individually.

Consider a dependency graph between calls p and q:

              B 
             / \  
  p ------ A/   \D ----- q
            \   /         
             \ /
              C  
                  
A depends on p,
B depends on A,
C depends on A,
D depends on C and B,
q depends on D.

These dependencies restrict how goals between p and q may be
scheduled.  For example, if the production of B may only be scheduled
in the same parallel conjunct or a later conjunct than the production
of A.

In some cases it may be possible to push one or more of these cheap
goals into one of the calls that use them.  When this is possible it
is desirable.  To break ties in these cases, these goals should be
pushed into the cheapest of the possible calls, this way the elapsed
time and dead time of the parallel conjunction is minimised.  Zoltan
said he'd be best to do this.  I think some profiler feedback
information will be useful, at least to give the costs of the calls so
that the best decision can be made.

   We don't need to implement this feature immediately, it's not too
   important for this paper.

In other cases the analysis tool should do a linear search to find the
best schedule, a later version of the tool should do a branch and
bound search over the 2^N search space to look for a more optimal
solution.  We will be able to test if the later search strategy is
better and finding optimal solutions.


Search space
------------

For each middle goal there are several placement options:

    Place the goal with the current conjunct,

    Start a new conjunct and place the goal in that.

That's two options per goal, which is a search space of 2^N.

In practice we can reduce this size by adding constraints, if the
current conjunct doesn't contain a costly call then a new conjunct may
not be started for example.  This constraint makes the search space
linear by only allowing one division in a group of middle goals.
However this is to simplistic.  We want to allow goals that are
involved in dependencies between two costly calls to be placed
independently.

The search space can be come much larger if we allow goals to be
re-ordered.

Branch and bound search
-----------------------

A branch and bound search can be written with non-deterministic
predicates, a mutable and a failure driven loop.  However Zoltan
recommends using deterministic predicates and tracking variable values
that have been tried.  There is a method for doing this with an
arbitrary number of variables.

  Note: We didn't do this, this suggestion was so that we could work
  out why we ran out of nondet stack space.

Each variable becomes a digit in the search space of the program, (if
you like to think geometrically, a dimension).  Increment the least
significant digit, if it overflows increment the next one and reset
the current one.  Do this until you've exhausted all the possible
values.  You will have to manage the addition and removal of variables
as the search tree deepens and back-tracks.

One can implement branch and bound simply by updating the best
solution found so far when a solution is found and continuing the
search.  Allow the user-code to access the best solution and update it
during runtime (we probably wont update it but it would be good to
support this).

When a decision is encountered the user code may have to pass a
continuation to the search code.


Convergence
===========

Our current Branch and bound search converges rather slowly.

It should use a cheap computation that computes the minimum value of
the objective function given that we haven't committed to some
decisions.  This can probably be done with a shortest path algorithm
or perhaps critical path algorithm (used in business project
planning).


Objective function
==================

 minimise ParTime * ParTimeWeight + Overheads * OverheadsWeight.

 ParTimeWeight = 1.0
 OverheadsWeight = 2.0

This allows us to select parallelisations minimise parallel execution
time.  It also lets us trade 1 unit of overheads for 2 less units of
execution time.  This helps us select more optimal parallelisations in
terms of overheads when they have similar execution times.  We should
do this for 'dead times' in the future also.

Dead times are when resources like a stack are used while computation
is blocked, that is the resource cannot be actively used by a
different task.

